<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Limits of the Quantitative Approach to Bias and Fairness – My Awesome CSCI 0451 Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6de787833effe4777a6777a5e05fb578.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Limits of the Quantitative Approach to Bias and Fairness</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In a thought-provoking 2022 speech at Princeton University, Arvind Narayanan asserted that “currently quantitative methods are primarily used to justify the status quo. I would argue that they do more harm than good” <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 25</a>)</span>. This provocative claim challenges foundational assumptions about how researchers study and address discrimination in algorithmic systems. As data-driven systems increasingly influence critical decisions across society—from hiring to lending to criminal justice—the methods we use to evaluate their fairness have profound consequences. This essay examines Narayanan’s position in conversation with other scholarly perspectives to assess whether quantitative approaches to discrimination truly cause more harm than good.</p>
<p>By analyzing Narayanan’s critique alongside key scholarly works including <em>Fairness and Machine Learning</em> <span class="citation" data-cites="barocasFairnessMachineLearning2023">(<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">Barocas, Hardt, and Narayanan 2023</a>)</span>, <em>Data Feminism</em> <span class="citation" data-cites="dignazioDataFeminism2023">(<a href="#ref-dignazioDataFeminism2023" role="doc-biblioref">D’Ignazio and Klein 2023</a>)</span>, and other contributions to the field, I will evaluate the strengths and limitations of quantitative methods in addressing algorithmic bias. Through discussion of both successful and disappointing case studies, I will argue that while Narayanan’s critique identifies crucial shortcomings in current practice, quantitative methods remain essential tools for fairness work when deployed with appropriate critical awareness and integrated into more holistic frameworks for understanding discrimination.</p>
</section>
<section id="narayanans-position" class="level2">
<h2 class="anchored" data-anchor-id="narayanans-position">Narayanan’s Position</h2>
<p>Narayanan’s critique of quantitative methods centers on how they can obscure rather than reveal discrimination. He outlines seven key limitations in current quantitative approaches to discrimination:</p>
<p>First, the null hypothesis in quantitative research typically assumes no discrimination exists, placing the burden of proof on those claiming discrimination. This framing is “not a logical inevitability… [but] a choice” <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 7</a>)</span> that inherently favors the status quo. When researchers assume no discrimination exists until proven otherwise, they create a structural barrier to detecting bias.</p>
<p>Second, most quantitative methods rely on snapshot datasets that fail to capture how discrimination compounds over time. Using a mathematical model, Narayanan demonstrates how “a 2.5% difference in quarterly performance reviews” can compound over 20 years to create “a 7-fold difference” in CEO demographics <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 9–10</a>)</span>. Such subtle discrimination falls “far below the threshold that’s detectable by quantitative methods” in a single timeframe.</p>
<p>Third, data about minoritized groups are often collected by the very institutions suspected of discrimination. This creates conflicts of interest where organizations control what data are collected and released, potentially hiding their own biases.</p>
<p>Fourth, quantitative research tends to advance by “explaining away discrimination” <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 12</a>)</span>. Academic incentives reward researchers who find omitted variables that can account for disparities, effectively controlling for the attributes that constitute discrimination itself.</p>
<p>Fifth, quantitative approaches often identify the wrong locus of intervention, suggesting that minoritized groups—rather than discriminatory systems—need fixing. Narayanan examines a study of gender pay gaps among Uber drivers that framed the 7% earnings gap as stemming from women’s choices rather than systemic factors, while ignoring that female drivers were “2.7 times as likely to drop off the platform” <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 13–14</a>)</span>.</p>
<p>Sixth, researchers cling to an objectivity illusion, despite making “at least 10-20 subjective choices” in a typical paper <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 16</a>)</span>. This illusion of neutrality masks how value judgments shape research design, variable selection, and interpretation.</p>
<p>Finally, through performativity, narrow statistical definitions of discrimination become operationalized as the only recognized forms of harm. When these metrics become the basis for policy, they limit what counts as actionable discrimination.</p>
<p>These limitations lead Narayanan to conclude that quantitative methods often “justify racism and excuse inaction” <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 3</a>)</span> by offering technical smokescreens that obscure structural discrimination.</p>
</section>
<section id="the-benefits-of-quantitative-methods" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits-of-quantitative-methods">The Benefits of Quantitative Methods</h2>
<p>Despite these limitations, quantitative methods have demonstrated unique value in addressing discrimination when thoughtfully applied. In chapter 3 of <em>Fairness and Machine Learning</em>, Barocas, Hardt, and Narayanan detail how formal statistical criteria can detect and mitigate bias in algorithmic systems. They outline several technical fairness notions, including independence (demographic parity), separation (equal error rates), and sufficiency (calibration by group) <span class="citation" data-cites="barocasFairnessMachineLearning2023">(<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">Barocas, Hardt, and Narayanan 2023</a>)</span>.</p>
<p>One particularly beneficial application referenced by Narayanan himself is Fishbane, Ouss, and Shah’s <span class="citation" data-cites="fishbane2020behavioral">(<a href="#ref-fishbane2020behavioral" role="doc-biblioref">2020</a>)</span> study of failure-to-appear rates in the New York City court system. This research exemplifies how quantitative methods can identify concrete intervention points that reduce disparities. In this study, researchers examined why defendants frequently missed court dates for low-level offenses, with particular attention to racial disparities in these rates.</p>
<p>From a technical perspective (Chapter 3), the study employed error rate analysis to measure disparities in court appearance rates across demographic groups. They analyzed patterns in failures to appear, identifying differential impacts on marginalized communities. Their approach relates to what Barocas, Hardt, and Narayanan call separation—ensuring “equal false negative rates” by identifying when different groups experience unequal burdens from the same system <span class="citation" data-cites="barocasFairnessMachineLearning2023">(<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">Barocas, Hardt, and Narayanan 2023</a>)</span>.</p>
<p>Their findings were revelatory: many defendants missed court dates not due to willful evasion but because of confusing summons forms and lack of reminders. The researchers then tested interventions by redesigning the forms and implementing text message reminders, which “drastically reduced the rate at which people failed to appear in court” <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 24</a>)</span>.</p>
<p>From a moral perspective (Chapter 4), this study embodied what Barocas, Hardt, and Narayanan describe as procedural fairness—ensuring all defendants had equal practical ability to comply with court requirements regardless of their resources or background. The intervention also addressed representational fairness by redesigning forms to be understandable regardless of education level or prior system knowledge <span class="citation" data-cites="barocasFairnessMachineLearning2023">(<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">Barocas, Hardt, and Narayanan 2023</a>)</span>.</p>
<p>Rather than treating failure to appear as evidence of individual moral failing (which might justify harsher penalties), the researchers recognized it as a system design problem—reflecting the moral principle that individuals should not be penalized for navigating poorly designed bureaucratic processes. This shifts the moral framing from individual culpability to systemic responsibility.</p>
<p>This case exemplifies how quantitative methods can productively expose discrimination when they: (1) identify concrete intervention points, (2) focus on system-level rather than individual-level problems, and (3) lead to practical solutions that reduce disparities.</p>
</section>
<section id="the-limitations-of-quantitative-methods" class="level2">
<h2 class="anchored" data-anchor-id="the-limitations-of-quantitative-methods">The Limitations of Quantitative Methods</h2>
<p>While some quantitative approaches succeed, others reinforce the problems Narayanan identifies. A particularly disappointing study Narayanan highlights is “The Gender Earnings Gap in the Gig Economy: Evidence from over a Million Rideshare Drivers” <span class="citation" data-cites="cook2018gender">(<a href="#ref-cook2018gender" role="doc-biblioref">Cook et al. 2018</a>)</span>, which examined the pay gap between male and female Uber drivers.</p>
<p>In technical terms from Chapter 3 of <em>Fairness and Machine Learning</em>, the study focused on disparate impact (the 7% earnings difference) while neglecting the more significant disparate treatment that might explain why female drivers were 2.7 times more likely to leave the platform. The researchers attributed the earnings gap solely to three factors: where drivers chose to drive, men’s greater experience on the platform, and men’s tendency to drive faster.</p>
<p>The authors claimed no gender discrimination existed in the platform’s algorithm or rider behavior. But as Narayanan notes, their analysis “explains away discrimination” by treating these factors as neutral preferences rather than potential responses to discriminatory conditions: “part of that is because some neighborhoods aren’t safe for women” and “some women face harassment” <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 14</a>)</span>.</p>
<p>From a moral perspective (Chapter 4), the study reflects what Barocas, Hardt, and Narayanan call the “difference principle” view of discrimination—treating statistical disparities as morally neutral if they can be explained by apparent preferences or choices. This neglects the broader moral context in which those choices occur. The study treats driver decisions as freely made preferences rather than constrained responses to structural inequities <span class="citation" data-cites="barocasFairnessMachineLearning2023">(<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">Barocas, Hardt, and Narayanan 2023</a>)</span>.</p>
<p>This exemplifies what <span class="citation" data-cites="selbst2019fairness">Selbst et al. (<a href="#ref-selbst2019fairness" role="doc-biblioref">2019</a>)</span> call the “framing trap”—where researchers narrowly define problems in ways that make technical solutions seem sufficient. By focusing on measurable earnings rather than broader experiences of discrimination, the study frames fairness as satisfied by statistical parity alone.</p>
<p>D’Ignazio and Klein would identify this as a failure to “consider context” and “examine power”—two key principles of Data Feminism <span class="citation" data-cites="dignazioDataFeminism2023">(<a href="#ref-dignazioDataFeminism2023" role="doc-biblioref">D’Ignazio and Klein 2023</a>)</span>. The researchers’ choice to focus on the smaller pay disparity while ignoring the larger retention disparity reveals how quantitative approaches can selectively measure what supports existing power structures while overlooking more significant indicators of systemic problems.</p>
<p>This case demonstrates how quantitative methods, when divorced from context and power analysis, can produce misleading conclusions that “justify the status quo rather than challenge it” <span class="citation" data-cites="corbettDaviesMeasureFairness2018">(<a href="#ref-corbettDaviesMeasureFairness2018" role="doc-biblioref">Corbett-Davies et al. 2018</a>)</span>. The technical transparency of numbers creates an illusion of objectivity that masks underlying value judgments about what constitutes discrimination and what counts as evidence.</p>
</section>
<section id="additional-scholarly-perspectives" class="level2">
<h2 class="anchored" data-anchor-id="additional-scholarly-perspectives">Additional Scholarly Perspectives</h2>
<p>Three additional scholarly sources provide important perspectives on the tension between quantitative methods and substantive fairness. <span class="citation" data-cites="corbettDaviesMeasureFairness2018">Corbett-Davies et al. (<a href="#ref-corbettDaviesMeasureFairness2018" role="doc-biblioref">2018</a>)</span> explore “The Measure and Mismeasure of Fairness” by showing how statistical fairness metrics can produce paradoxical outcomes—situations where satisfying a formal fairness criterion may actually harm the very groups it aims to protect. For example, requiring equal false positive rates across racial groups in pretrial risk assessment might lead to higher overall detention rates for marginalized groups if baseline risk levels differ.</p>
<p><span class="citation" data-cites="selbst2019fairness">Selbst et al. (<a href="#ref-selbst2019fairness" role="doc-biblioref">2019</a>)</span> identify five “abstraction traps” in fair ML research where technical fixes fail to account for nuanced social realities. Their insight that technical tools often divorce data from their social origins aligns with Narayanan’s critiques of snapshot datasets and decontextualized analysis. They argue that “fairness” becomes dangerous when reduced to a purely technical problem, divorced from the social contexts that give it meaning.</p>
<p><span class="citation" data-cites="green2022substantive">Green (<a href="#ref-green2022substantive" role="doc-biblioref">2022</a>)</span> articulates a crucial distinction between “formal” and “substantive” algorithmic fairness. While formal fairness focuses on satisfying statistical criteria, substantive fairness requires examining whether an algorithm contributes to genuine justice outcomes. Green argues that even mathematically “fair” algorithms can encode and perpetuate injustice if they naturalize existing inequalities. This distinction parallels Narayanan’s concern that quantitative methods often identify the wrong locus of intervention.</p>
<p><em>Data Feminism</em> <span class="citation" data-cites="dignazioDataFeminism2023">(<a href="#ref-dignazioDataFeminism2023" role="doc-biblioref">D’Ignazio and Klein 2023</a>)</span> offers the most comprehensive framework for addressing Narayanan’s concerns. Their principles of “examine power,” “challenge power,” and “consider context” directly respond to the limitations Narayanan identifies. Through examples like the Anti-Eviction Mapping Project (Chapter 5) and their critique of “Big Dick Data” projects that “ignore context, fetishize size, and inflate their technical and scientific capabilities” (Chapter 6, p.&nbsp;4), they demonstrate how attention to power dynamics can transform quantitative methods from tools of oppression into instruments of liberation.</p>
</section>
<section id="taking-a-position" class="level2">
<h2 class="anchored" data-anchor-id="taking-a-position">Taking a Position</h2>
<p>In light of these analyses, I find myself in qualified agreement with Narayanan’s assertion that “quantitative methods are primarily used to justify the status quo” and often “do more harm than good” <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 25</a>)</span>. The evidence from case studies and scholarly analyses shows how traditional applications of quantitative methods can indeed mask discrimination rather than expose it.</p>
<p>However, my agreement comes with important qualifications. First, Narayanan himself acknowledges that the problem lies not with quantitative methods per se, but with how they are deployed. He states, “If things were different—if the 79 percent of engineers at Google who are male were specifically trained in structural oppression before building their data systems… then their overrepresentation might be very slightly less of a problem” <span class="citation" data-cites="narayanan2022limits">(<a href="#ref-narayanan2022limits" role="doc-biblioref">Narayanan 2022, 13</a>)</span>. This suggests that quantitative methods, when embedded in a framework that addresses power and context, could help advance justice.</p>
<p>Second, cases like the court appearance study demonstrate that quantitative methods can identify concrete intervention points for reducing disparities. When paired with a critical understanding of systemic injustice, numbers can provide actionable evidence for meaningful reform.</p>
<p>The path forward, I believe, requires integrating quantitative precision with what <span class="citation" data-cites="green2022substantive">Green (<a href="#ref-green2022substantive" role="doc-biblioref">2022</a>)</span> calls “substantive algorithmic fairness”—an approach that goes beyond statistical metrics to consider whether algorithms contribute to substantive justice. This means reversing the null hypothesis to assume discrimination exists unless proven otherwise, collecting longitudinal data that captures compounding effects, focusing on systemic rather than individual-level interventions, engaging directly with affected communities, and treating quantitative evidence as one component in a broader justice framework. By shifting these fundamental assumptions and practices, quantitative methods can become tools for exposing rather than obscuring discrimination.</p>
<p>As D’Ignazio and Klein assert, “the data never, ever ‘speak for themselves’” <span class="citation" data-cites="dignazioDataFeminism2023">(<a href="#ref-dignazioDataFeminism2023" role="doc-biblioref">D’Ignazio and Klein 2023, chap. 6</a>)</span>. Acknowledging this truth allows us to use quantitative methods more responsibly—not as neutral arbiters of truth, but as tools that must be wielded with care, context, and a commitment to challenging rather than reinforcing existing power structures.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Narayanan’s critique of quantitative methods provides a vital caution against simplistic faith in data-driven solutions to discrimination. The limitations he identifies—from problematic null hypotheses to the illusion of objectivity—reveal how seemingly neutral methods can entrench injustice.</p>
<p>Yet certain quantitative approaches, like the court appearance study, demonstrate potential for meaningful reform. The key difference lies not in whether numbers are used, but in how they are contextualized, what questions they seek to answer, and whether they serve to challenge or legitimize existing power structures.</p>
<p>As D’Ignazio and Klein remind us in <em>Data Feminism</em>, data work is always political. The question is not whether to use quantitative methods, but how to use them in ways that acknowledge power, consider context, and work toward substantive justice. By approaching quantitative methods with a critical eye and integrating them within a broader commitment to equity, we can transform them from tools that primarily justify the status quo into instruments of lasting change.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-barocasFairnessMachineLearning2023" class="csl-entry" role="listitem">
Barocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. <em>Fairness and <span>Machine Learning</span>: <span>Limitations</span> and <span>Opportunities</span></em>. <span>Cambridge, Massachusetts</span>: <span>The MIT Press</span>.
</div>
<div id="ref-cook2018gender" class="csl-entry" role="listitem">
Cook, Cody, Rebecca Diamond, Jonathan Hall, John A. List, and Paul Oyer. 2018. <span>“The <span>Gender Earnings Gap</span> in the <span>Gig Economy</span>: <span>Evidence</span> from over a <span>Million Rideshare Drivers</span>.”</span> <em>National Bureau of Economic Research</em>. <a href="https://doi.org/10.3386/w24732">https://doi.org/10.3386/w24732</a>.
</div>
<div id="ref-corbettDaviesMeasureFairness2018" class="csl-entry" role="listitem">
Corbett-Davies, Sam, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. 2018. <span>“The <span>Measure</span> and <span>Mismeasure</span> of <span>Fairness</span>: <span>A Critical Review</span> of <span>Fair Machine Learning</span>.”</span> <em>arXiv Preprint</em>. <a href="https://arxiv.org/abs/1808.00023">https://arxiv.org/abs/1808.00023</a>.
</div>
<div id="ref-dignazioDataFeminism2023" class="csl-entry" role="listitem">
D’Ignazio, Catherine, and Lauren F. Klein. 2023. <em>Data <span>Feminism</span></em>. First MIT Press paperback edition. <span>Cambridge, Massachusetts</span>: <span>The MIT Press</span>.
</div>
<div id="ref-fishbane2020behavioral" class="csl-entry" role="listitem">
Fishbane, Alissa, Aurelie Ouss, and Anuj K. Shah. 2020. <span>“Behavioral Nudges Reduce Failure to Appear for Court.”</span> <em>Science</em> 370 (6517). <a href="https://doi.org/10.1126/science.abb6591">https://doi.org/10.1126/science.abb6591</a>.
</div>
<div id="ref-green2022substantive" class="csl-entry" role="listitem">
Green, Ben. 2022. <span>“Escaping the <span>Impossibility</span> of <span>Fairness</span>: <span>From Formal</span> to <span>Substantive Algorithmic Fairness</span>.”</span> <em>Philosophy &amp; Technology</em> 35 (3): 1–24. <a href="https://doi.org/10.1007/s13347-022-00538-y">https://doi.org/10.1007/s13347-022-00538-y</a>.
</div>
<div id="ref-narayanan2022limits" class="csl-entry" role="listitem">
Narayanan, Arvind. 2022. <span>“The Limits of the Quantitative Approach to Discrimination.”</span> 2022 James Baldwin lecture, Princeton University.
</div>
<div id="ref-selbst2019fairness" class="csl-entry" role="listitem">
Selbst, Andrew D., Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. <span>“Fairness and Abstraction in Sociotechnical Systems.”</span> In <em>Proceedings of the Conference on Fairness, Accountability, and Transparency</em>, 59–68. <span>New York, NY, USA</span>: <span>ACM</span>. <a href="https://doi.org/10.1145/3287560.3287598">https://doi.org/10.1145/3287560.3287598</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>